{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from hmmlearn import hmm\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "sys.path.insert(1, '/mnt/c/Users/dalli/source/acme_senior/_projectV3/CarKalmanFilter/')\n",
    "\n",
    "\n",
    "import cleaner\n",
    "import filter\n",
    "from kalman import KalmanFilter\n",
    "\n",
    "wsl = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tables and images are from https://www.kaggle.com/code/jefmenegazzo/road-surface-type-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Hardware       | Sensor         | Data                                 | Sampling Rate |\n",
    "|----------------|----------------|--------------------------------------|---------------|\n",
    "| HP Webcam HD-4110 | Camera      | 720p Video                           | 30 Hz         |\n",
    "| Xiaomi Mi 8       | GPS         | Speed in m/s, latitude, longitude, etc. | 1 Hz       |\n",
    "| MPU-9250          | Accelerometer | 3-axis acceleration in m/s²         | 100 Hz        |\n",
    "| MPU-9250          | Gyroscope    | 3-axis rotation rate in deg/s        | 100 Hz        |\n",
    "| MPU-9250          | Magnetometer | 3-axis ambient geomagnetic field in µT | 100 Hz       |\n",
    "| MPU-9250          | Temperature  | Sensor temperature in ◦C              | 100 Hz       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| DataSet | Vehicle              | Driver   | Scenario  | Distance |\n",
    "|---------|----------------------|----------|-----------|----------|\n",
    "| PVS 1   | Volkswagen Saveiro   | Driver 1 | Scenario 1| 13.81 km |\n",
    "| PVS 2   | Volkswagen Saveiro   | Driver 1 | Scenario 2| 11.62 km |\n",
    "| PVS 3   | Volkswagen Saveiro   | Driver 1 | Scenario 3| 10.72 km |\n",
    "| PVS 4   | Fiat Bravo           | Driver 2 | Scenario 1| 13.81 km |\n",
    "| PVS 5   | Fiat Bravo           | Driver 2 | Scenario 2| 11.63 km |\n",
    "| PVS 6   | Fiat Bravo           | Driver 2 | Scenario 3| 10.73 km |\n",
    "| PVS 7   | Fiat Palio           | Driver 3 | Scenario 1| 13.78 km |\n",
    "| PVS 8   | Fiat Palio           | Driver 3 | Scenario 2| 11.63 km |\n",
    "| PVS 9   | Fiat Palio           | Driver 3 | Scenario 3| 10.74 km |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| File                   | Description                                                                                       |\n",
    "|------------------------|---------------------------------------------------------------------------------------------------|\n",
    "| dataset_gps.csv        | GPS data, including latitude, longitude, altitude, speed, accuracy, etc.                         |\n",
    "| dataset_gps_mpu_left.csv  | Inertial sensor data on the left side of the vehicle, combined with GPS data.                     |\n",
    "| dataset_gps_mpu_right.csv | Inertial sensor data on the right side of the vehicle, combined with GPS data.                    |\n",
    "| dataset_labels.csv       | Data classes for each sample data in the dataset (for both sides).                                  |\n",
    "| dataset_mpu_left.csv     | Inertial sensor data on the left side of the vehicle.                                              |\n",
    "| dataset_mpu_right.csv    | Inertial sensor data on the right side of the vehicle.                                             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Map of paths](./maps.png \"All paths driven by the three drivers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if wsl:\n",
    "    parent = '/mnt/c/Users/dalli/source/acme_senior/_projectV3/CarKalmanFilter/.data'\n",
    "else:\n",
    "    parent = \".data\"\n",
    "data_dict = cleaner.clean_dict(cleaner.load_data(parent, exclude_test=[\"PVS 7\", \"PVS 8\"], exclude_val=[\"PVS 9\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  train: \n",
      " \t t_gps: \n",
      " \t\t PVS 1: (1458, 11)\n",
      " \t\t PVS 2: (1551, 11)\n",
      " \t\t PVS 3: (1316, 11)\n",
      " \t\t PVS 4: (1432, 11)\n",
      " \t\t PVS 5: (1263, 11)\n",
      " \t\t PVS 6: (915, 11)\n",
      " \t gps_mpu_left: \n",
      " \t\t PVS 1: (144036, 26)\n",
      " \t\t PVS 2: (124684, 26)\n",
      " \t\t PVS 3: (105816, 26)\n",
      " \t\t PVS 4: (132492, 26)\n",
      " \t\t PVS 5: (133877, 26)\n",
      " \t\t PVS 6: (96279, 26)\n",
      " \t gps_mpu_right: \n",
      " \t\t PVS 1: (144036, 26)\n",
      " \t\t PVS 2: (124684, 26)\n",
      " \t\t PVS 3: (105816, 26)\n",
      " \t\t PVS 4: (132492, 26)\n",
      " \t\t PVS 5: (133877, 26)\n",
      " \t\t PVS 6: (96279, 26)\n",
      " \t labels: \n",
      " \t\t PVS 1: (144036, 14)\n",
      " \t\t PVS 2: (124684, 14)\n",
      " \t\t PVS 3: (105816, 14)\n",
      " \t\t PVS 4: (132492, 14)\n",
      " \t\t PVS 5: (133877, 14)\n",
      " \t\t PVS 6: (96279, 14)\n",
      " \t folders: 6\n",
      "  val: \n",
      " \t t_gps: \n",
      " \t\t PVS 9: (999, 11)\n",
      " \t gps_mpu_left: \n",
      " \t\t PVS 9: (91555, 26)\n",
      " \t gps_mpu_right: \n",
      " \t\t PVS 9: (91555, 26)\n",
      " \t labels: \n",
      " \t\t PVS 9: (91555, 14)\n",
      " \t folders: 1\n",
      "  test: \n",
      " \t t_gps: \n",
      " \t\t PVS 7: (1281, 11)\n",
      " \t\t PVS 8: (1134, 11)\n",
      " \t gps_mpu_left: \n",
      " \t\t PVS 7: (128548, 26)\n",
      " \t\t PVS 8: (123618, 26)\n",
      " \t gps_mpu_right: \n",
      " \t\t PVS 7: (128548, 26)\n",
      " \t\t PVS 8: (123618, 26)\n",
      " \t labels: \n",
      " \t\t PVS 7: (128548, 14)\n",
      " \t\t PVS 8: (123618, 14)\n",
      " \t folders: 2"
     ]
    }
   ],
   "source": [
    "cleaner.print_structure(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter.add_smoothed_cols(data_dict, window=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter.add_diff_cols(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1458"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict[\"train\"][\"t_gps\"][\"PVS 1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_z_dash(df, type=\"train\", road=\"good_road_left\"):\n",
    "    \"\"\"\n",
    "    Builds a 1 column dataset from the given dictionary of dataframes\n",
    "    timestamp\n",
    "    latitude\n",
    "    longitude\n",
    "    elevation\n",
    "    acc_x_dash_smooth\n",
    "    acc_y_dash_smooth\n",
    "    acc_z_dash_smooth\n",
    "\n",
    "    :param df: dataframe\n",
    "    :param type: string\n",
    "\n",
    "    :return: dataframe with only the acc_z_dash column\n",
    "    \"\"\"\n",
    "    result = None\n",
    "    lengths = []\n",
    "    for folder in df[type][\"gps_mpu_left\"].keys():\n",
    "        pvsi = df[type][\"gps_mpu_left\"][folder]\n",
    "        labels = df[type][\"labels\"][folder][road]\n",
    "        indices = labels[labels == 1].index\n",
    "\n",
    "        new_data = pvsi.loc[indices]\n",
    "        lengths.append(len(new_data))\n",
    "\n",
    "        if result is None:\n",
    "            result = new_data\n",
    "        else:\n",
    "            # append on the same column\n",
    "            result = pd.concat([result, new_data], axis=0)\n",
    "    \n",
    "\n",
    "\n",
    "def build_gps_data(df, type=\"train\"):\n",
    "    \"\"\"\n",
    "    Builds a 6 column dataset from the given dataframe\n",
    "\n",
    "    :param df: dataframe\n",
    "    :param type: string\n",
    "\n",
    "    :return: dataframe with only the acc_z_dash column\n",
    "    :return: list of lengths\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for folder in df[type][\"gps_mpu_left\"].keys():\n",
    "        pvsi = df[type][\"gps_mpu_left\"][folder][[\"timestamp\", \"meters_latitude\", \"meters_longitude\", \"acc_x_dash_smooth\", \"acc_y_dash_smooth\", \"acc_z_dash_smooth\"]]\n",
    "        elevation = df[type][\"t_gps\"][folder][[\"timestamp\", \"meters_elevation\"]]\n",
    "\n",
    "        # merge the two dataframes on timestamp then remove timestamp\n",
    "        pvsi = pd.merge(pvsi, elevation, on=\"timestamp\")\n",
    "        pvsi = pvsi.drop(columns=[\"timestamp\"])\n",
    "\n",
    "        result[folder] = pvsi\n",
    "    return result\n",
    "\n",
    "\n",
    "train_dict = {\n",
    "    \"good\": build_z_dash(data_dict, type=\"train\", road=\"good_road_left\"),\n",
    "    \"regular\": build_z_dash(data_dict, type=\"train\", road=\"regular_road_left\"),\n",
    "    \"bad\": build_z_dash(data_dict, type=\"train\", road=\"bad_road_left\")\n",
    "}\n",
    "\n",
    "test_dict = {\n",
    "    \"good\": build_z_dash(data_dict, type=\"test\", road=\"good_road_left\"),\n",
    "    \"regular\": build_z_dash(data_dict, type=\"test\", road=\"regular_road_left\"),\n",
    "    \"bad\": build_z_dash(data_dict, type=\"test\", road=\"bad_road_left\")\n",
    "}\n",
    "\n",
    "kal_data = build_gps_data(data_dict, type=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kal_data[\"PVS 1\"][\"meters_latitude\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(6, 1024)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (6,6) (3,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5263/957894384.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKalmanFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/c/Users/dalli/source/acme_senior/_projectV3/CarKalmanFilter/kalman.py\u001b[0m in \u001b[0;36mestimate\u001b[0;34m(self, x0, P0, z, return_norms)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;31m# update step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0myh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mH\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mxk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mSk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mH\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mpk\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mKk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpk\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mxk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mKk\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0myh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (6,6) (3,3) "
     ]
    }
   ],
   "source": [
    "# STATE SPACE (X)\n",
    "# x pos\n",
    "# y pos\n",
    "# z pos\n",
    "# x vel\n",
    "# y vel\n",
    "# z vel\n",
    "# x acc\n",
    "# y acc\n",
    "# z acc\n",
    "dt = 0.001\n",
    "\n",
    "# STATE SPACE PRIME (X')\n",
    "# x pos + dt * x vel\n",
    "# y pos + dt * y vel\n",
    "# z pos + dt * z vel\n",
    "# x vel + dt * x acc\n",
    "# y vel + dt * y acc\n",
    "# z vel + dt * z acc\n",
    "# x acc\n",
    "# y acc\n",
    "# z acc\n",
    "\n",
    "# OBSERVATION SPACE (Z)\n",
    "# x pos + noise\n",
    "# y pos + noise\n",
    "# z pos + noise\n",
    "\n",
    "\n",
    "Q = np.eye(9) * 0.1\n",
    "R = np.eye(3) * 10\n",
    "\n",
    "F = np.zeros((9, 9))\n",
    "for i in range(6):\n",
    "    F[i, i + 3] = dt\n",
    "\n",
    "G = np.zeros((9, 3))\n",
    "for i in range(3):\n",
    "    G[i + 6, i] = dt\n",
    "\n",
    "H = np.zeros((6, 9))\n",
    "for i in range(3):\n",
    "    H[i, i] = dt\n",
    "    H[i + 3, i + 6] = dt\n",
    "\n",
    "# initial state\n",
    "x0 = np.zeros(9)\n",
    "P0 = 1e5 * Q\n",
    "z = kal_data[\"PVS 1\"].to_numpy().T\n",
    "print(type(z))\n",
    "print(z.shape)\n",
    "tsteps = 1000\n",
    "\n",
    "# control u\n",
    "u = np.zeros(3)\n",
    "\n",
    "kf = KalmanFilter(F, Q, H, R, G, u)\n",
    "est = kf.estimate(x0, P0, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(est[0,:], est[1,:], label=\"Estimated Position\")\n",
    "plt.scatter(z[0,:], z[1,:], label=\"Observations\", s = 1, c=\"g\")\n",
    "plt.title(\"Observations and estimated position\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM\n",
    "\n",
    "I got it to run (it turns out that you can only include one series as your input data) but it doesn't work. I think the HMM decided that zeros are local minimums or values below a threshold and pretty much everything else is ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for good: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 1, 2, \n",
      "Training for regular: 0, 1, 2, \n",
      "Training for bad: 0, 1, 2, "
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "num_models = 3\n",
    "for key in train_dict.keys():\n",
    "    data, lengths = train_dict[key]\n",
    "    # make data an array\n",
    "    data = data.values.reshape(-1, 1)\n",
    "    # hmmlearn expects the data to be in a single array:\n",
    "    # To separate the sequences, it requires the length of each:\n",
    "    print(\"\\nTraining for\", key, end=\": \")\n",
    "\n",
    "    best_log = -np.inf\n",
    "    for i in range(num_models):\n",
    "        # Initialize and train the model\n",
    "        model = hmm.GMMHMM(n_components=6, covariance_type=\"diag\")\n",
    "        model.fit(data, lengths=lengths)\n",
    "        # Check the log-likelihood\n",
    "        log_likelihood = model.monitor_.history[-1]\n",
    "        if log_likelihood > best_log:\n",
    "            best_log = log_likelihood\n",
    "            best_model = model\n",
    "        print(i, end=\", \")\n",
    "    models[key] = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for good : 0.9090909090909091\n",
      "Accuracy for regular : 0.6\n",
      "Accuracy for bad : 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# predicted_labels = model.predict(X)\n",
    "\n",
    "def predict(mfcc_coeffs):\n",
    "    \"\"\"\n",
    "    Predict the word from the given mfcc coefficients\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mfcc_coeffs : ndarray of shape (M,)\n",
    "        The mfcc coefficients for the word to be predicted\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    word : str\n",
    "        The predicted word\n",
    "    \"\"\"\n",
    "    # find the log probability density of the given mfcc coefficients\n",
    "    log_prob = {}\n",
    "    for key in models.keys():\n",
    "        log_prob[key] = models[key].score(mfcc_coeffs)\n",
    "    \n",
    "    # return the word with the highest probability\n",
    "    return max(log_prob, key=log_prob.get)\n",
    "\n",
    "\n",
    "\n",
    "time_window = 10 # seconds\n",
    "time_window *= 1000\n",
    "for key in test_dict.keys():\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    test_data, _ = test_dict[key]\n",
    "\n",
    "    # iterate over test_data in groups of 10000\n",
    "    test_data = test_data.values.reshape(-1, 1)\n",
    "    for i in range(0, len(test_data), time_window):\n",
    "        item = test_data[i:i+time_window]\n",
    "        prediction = predict(item)\n",
    "        if prediction == key:\n",
    "            correct += 1\n",
    "        elif prediction == \"good\" and key == \"regular\":\n",
    "            correct += 1\n",
    "        elif prediction == \"regular\" and key == \"good\":\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "    \n",
    "    print(\"Accuracy for\", key, \":\", correct/(correct+incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1813/3682354438.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# how many times does predicted_labels switch form 0 to 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mswitches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mswitches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predicted_labels' is not defined"
     ]
    }
   ],
   "source": [
    "# how many times does predicted_labels switch form 0 to 1\n",
    "switches = 0\n",
    "for i in range(1, len(predicted_labels)):\n",
    "    if predicted_labels[i] != predicted_labels[i-1]:\n",
    "        switches += 1\n",
    "\n",
    "print(f\"Switches: {switches}\")\n",
    "print(f\"Lenght of labels: {len(predicted_labels)}\") \n",
    "print(f\"Ratio: {switches/len(predicted_labels)}\")\n",
    "\n",
    "# plot the predicted labels\n",
    "start = 20000\n",
    "end = 21000\n",
    "diff = 1000\n",
    "plt.figure(figsize=(20, 20))\n",
    "p = 1\n",
    "while p < 20:\n",
    "    plt.subplot(5, 4, max(p,1))\n",
    "    p += 1\n",
    "    start += diff\n",
    "    end += diff   \n",
    "    a = predicted_labels[start:end]\n",
    "    # count how many zeros\n",
    "    zeros = np.count_nonzero(a == 0)\n",
    "    # print(\"Zeros: \", zeros)\n",
    "    # print(\"P:\", p)\n",
    "    if zeros == 0:\n",
    "        p -= 1\n",
    "        continue\n",
    "    plt.scatter(np.arange(diff), predicted_labels[start:end])\n",
    "    plt.plot(np.arange(diff), hmm_true['paved_road'][start:end], color='red')\n",
    "    plt.plot(np.arange(diff), X[start:end, 0]-9.5, color='green')\n",
    "    plt.title(f\"Second {end/1000}, Zeros: {zeros}\")\n",
    "    # remove axis ticks\n",
    "    # plt.xticks([])\n",
    "    # plt.yticks([])\n",
    "\n",
    "# reduce space between subplots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
