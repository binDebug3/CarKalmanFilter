{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from hmmlearn import hmm\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "sys.path.insert(1, '/mnt/c/Users/dalli/source/acme_senior/_projectV3/CarKalmanFilter/')\n",
    "\n",
    "\n",
    "import cleaner\n",
    "import filter\n",
    "from kalman import KalmanFilter\n",
    "\n",
    "wsl = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tables and images are from https://www.kaggle.com/code/jefmenegazzo/road-surface-type-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Hardware       | Sensor         | Data                                 | Sampling Rate |\n",
    "|----------------|----------------|--------------------------------------|---------------|\n",
    "| HP Webcam HD-4110 | Camera      | 720p Video                           | 30 Hz         |\n",
    "| Xiaomi Mi 8       | GPS         | Speed in m/s, latitude, longitude, etc. | 1 Hz       |\n",
    "| MPU-9250          | Accelerometer | 3-axis acceleration in m/s²         | 100 Hz        |\n",
    "| MPU-9250          | Gyroscope    | 3-axis rotation rate in deg/s        | 100 Hz        |\n",
    "| MPU-9250          | Magnetometer | 3-axis ambient geomagnetic field in µT | 100 Hz       |\n",
    "| MPU-9250          | Temperature  | Sensor temperature in ◦C              | 100 Hz       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| DataSet | Vehicle              | Driver   | Scenario  | Distance |\n",
    "|---------|----------------------|----------|-----------|----------|\n",
    "| PVS 1   | Volkswagen Saveiro   | Driver 1 | Scenario 1| 13.81 km |\n",
    "| PVS 2   | Volkswagen Saveiro   | Driver 1 | Scenario 2| 11.62 km |\n",
    "| PVS 3   | Volkswagen Saveiro   | Driver 1 | Scenario 3| 10.72 km |\n",
    "| PVS 4   | Fiat Bravo           | Driver 2 | Scenario 1| 13.81 km |\n",
    "| PVS 5   | Fiat Bravo           | Driver 2 | Scenario 2| 11.63 km |\n",
    "| PVS 6   | Fiat Bravo           | Driver 2 | Scenario 3| 10.73 km |\n",
    "| PVS 7   | Fiat Palio           | Driver 3 | Scenario 1| 13.78 km |\n",
    "| PVS 8   | Fiat Palio           | Driver 3 | Scenario 2| 11.63 km |\n",
    "| PVS 9   | Fiat Palio           | Driver 3 | Scenario 3| 10.74 km |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| File                   | Description                                                                                       |\n",
    "|------------------------|---------------------------------------------------------------------------------------------------|\n",
    "| dataset_gps.csv        | GPS data, including latitude, longitude, altitude, speed, accuracy, etc.                         |\n",
    "| dataset_gps_mpu_left.csv  | Inertial sensor data on the left side of the vehicle, combined with GPS data.                     |\n",
    "| dataset_gps_mpu_right.csv | Inertial sensor data on the right side of the vehicle, combined with GPS data.                    |\n",
    "| dataset_labels.csv       | Data classes for each sample data in the dataset (for both sides).                                  |\n",
    "| dataset_mpu_left.csv     | Inertial sensor data on the left side of the vehicle.                                              |\n",
    "| dataset_mpu_right.csv    | Inertial sensor data on the right side of the vehicle.                                             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Map of paths](./maps.png \"All paths driven by the three drivers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if wsl:\n",
    "    parent = '/mnt/c/Users/dalli/source/acme_senior/_projectV3/CarKalmanFilter/.data'\n",
    "else:\n",
    "    parent = \".data\"\n",
    "data_dict = cleaner.clean_dict(cleaner.load_data(parent, exclude_test=[\"PVS 7\", \"PVS 8\"], exclude_val=[\"PVS 9\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  train: \n",
      " \t t_gps: \n",
      " \t\t PVS 1: (1458, 11)\n",
      " \t\t PVS 2: (1551, 11)\n",
      " \t\t PVS 3: (1316, 11)\n",
      " \t\t PVS 4: (1432, 11)\n",
      " \t\t PVS 5: (1263, 11)\n",
      " \t\t PVS 6: (915, 11)\n",
      " \t gps_mpu_left: \n",
      " \t\t PVS 1: (144036, 26)\n",
      " \t\t PVS 2: (124684, 26)\n",
      " \t\t PVS 3: (105816, 26)\n",
      " \t\t PVS 4: (132492, 26)\n",
      " \t\t PVS 5: (133877, 26)\n",
      " \t\t PVS 6: (96279, 26)\n",
      " \t gps_mpu_right: \n",
      " \t\t PVS 1: (144036, 26)\n",
      " \t\t PVS 2: (124684, 26)\n",
      " \t\t PVS 3: (105816, 26)\n",
      " \t\t PVS 4: (132492, 26)\n",
      " \t\t PVS 5: (133877, 26)\n",
      " \t\t PVS 6: (96279, 26)\n",
      " \t labels: \n",
      " \t\t PVS 1: (144036, 14)\n",
      " \t\t PVS 2: (124684, 14)\n",
      " \t\t PVS 3: (105816, 14)\n",
      " \t\t PVS 4: (132492, 14)\n",
      " \t\t PVS 5: (133877, 14)\n",
      " \t\t PVS 6: (96279, 14)\n",
      " \t folders: 6\n",
      "  val: \n",
      " \t t_gps: \n",
      " \t\t PVS 9: (999, 11)\n",
      " \t gps_mpu_left: \n",
      " \t\t PVS 9: (91555, 26)\n",
      " \t gps_mpu_right: \n",
      " \t\t PVS 9: (91555, 26)\n",
      " \t labels: \n",
      " \t\t PVS 9: (91555, 14)\n",
      " \t folders: 1\n",
      "  test: \n",
      " \t t_gps: \n",
      " \t\t PVS 7: (1281, 11)\n",
      " \t\t PVS 8: (1134, 11)\n",
      " \t gps_mpu_left: \n",
      " \t\t PVS 7: (128548, 26)\n",
      " \t\t PVS 8: (123618, 26)\n",
      " \t gps_mpu_right: \n",
      " \t\t PVS 7: (128548, 26)\n",
      " \t\t PVS 8: (123618, 26)\n",
      " \t labels: \n",
      " \t\t PVS 7: (128548, 14)\n",
      " \t\t PVS 8: (123618, 14)\n",
      " \t folders: 2"
     ]
    }
   ],
   "source": [
    "cleaner.print_structure(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter.add_smoothed_cols(data_dict, window=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter.add_diff_cols(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1458"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict[\"train\"][\"t_gps\"][\"PVS 1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_z_dash(df, type=\"train\", road=\"good_road_left\"):\n",
    "    \"\"\"\n",
    "    Builds a 1 column dataset from the given dictionary of dataframes\n",
    "    timestamp\n",
    "    latitude\n",
    "    longitude\n",
    "    elevation\n",
    "    acc_x_dash_smooth\n",
    "    acc_y_dash_smooth\n",
    "    acc_z_dash_smooth\n",
    "\n",
    "    :param df: dataframe\n",
    "    :param type: string\n",
    "\n",
    "    :return: dataframe with only the acc_z_dash column\n",
    "    :return: list of lengths\n",
    "    \"\"\"\n",
    "    result = None\n",
    "    lengths = []\n",
    "    for folder in df[type][\"gps_mpu_left\"].keys():\n",
    "        pvsi = df[type][\"gps_mpu_left\"][folder]\n",
    "        labels = df[type][\"labels\"][folder][road]\n",
    "        indices = labels[labels == 1].index\n",
    "\n",
    "        new_data = pvsi.loc[indices][\"acc_z_dash_smooth\"]\n",
    "        lengths.append(len(new_data))\n",
    "\n",
    "        if result is None:\n",
    "            result = new_data\n",
    "        else:\n",
    "            # append on the same column\n",
    "            result = pd.concat([result, new_data], axis=0)\n",
    "    return result, lengths\n",
    "    \n",
    "\n",
    "\n",
    "def build_gps_data(df, type=\"train\"):\n",
    "    \"\"\"\n",
    "    Builds a 6 column dataset from the given dataframe\n",
    "\n",
    "    :param df: dataframe\n",
    "    :param type: string\n",
    "\n",
    "    :return: dataframe with only the acc_z_dash column\n",
    "    :return: list of lengths\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for folder in df[type][\"gps_mpu_left\"].keys():\n",
    "        pvsi = df[type][\"gps_mpu_left\"][folder][[\"timestamp\", \"meters_latitude\", \"meters_longitude\", \"acc_x_dash_smooth\", \"acc_y_dash_smooth\", \"acc_z_dash_smooth\"]]\n",
    "        elevation = df[type][\"t_gps\"][folder][[\"timestamp\", \"meters_elevation\"]]\n",
    "\n",
    "        # merge the two dataframes on timestamp then remove timestamp\n",
    "        pvsi = pd.merge(pvsi, elevation, on=\"timestamp\")\n",
    "        pvsi = pvsi.drop(columns=[\"timestamp\"])\n",
    "\n",
    "        result[folder] = pvsi\n",
    "    return result\n",
    "\n",
    "\n",
    "train_dict = {\n",
    "    \"good\": build_z_dash(data_dict, type=\"train\", road=\"good_road_left\"),\n",
    "    \"regular\": build_z_dash(data_dict, type=\"train\", road=\"regular_road_left\"),\n",
    "    \"bad\": build_z_dash(data_dict, type=\"train\", road=\"bad_road_left\")\n",
    "}\n",
    "\n",
    "test_dict = {\n",
    "    \"good\": build_z_dash(data_dict, type=\"test\", road=\"good_road_left\"),\n",
    "    \"regular\": build_z_dash(data_dict, type=\"test\", road=\"regular_road_left\"),\n",
    "    \"bad\": build_z_dash(data_dict, type=\"test\", road=\"bad_road_left\")\n",
    "}\n",
    "\n",
    "kal_data = build_gps_data(data_dict, type=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kal_data[\"PVS 1\"][\"meters_latitude\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # STATE SPACE (X)\n",
    "# # x pos\n",
    "# # y pos\n",
    "# # z pos\n",
    "# # x vel\n",
    "# # y vel\n",
    "# # z vel\n",
    "# # x acc\n",
    "# # y acc\n",
    "# # z acc\n",
    "# dt = 0.001\n",
    "\n",
    "# # STATE SPACE PRIME (X')\n",
    "# # x pos + dt * x vel\n",
    "# # y pos + dt * y vel\n",
    "# # z pos + dt * z vel\n",
    "# # x vel + dt * x acc\n",
    "# # y vel + dt * y acc\n",
    "# # z vel + dt * z acc\n",
    "# # x acc\n",
    "# # y acc\n",
    "# # z acc\n",
    "\n",
    "# # OBSERVATION SPACE (Z)\n",
    "# # x pos + noise\n",
    "# # y pos + noise\n",
    "# # z pos + noise\n",
    "\n",
    "\n",
    "# Q = np.eye(9) * 0.1\n",
    "# R = np.eye(3) * 10\n",
    "\n",
    "# F = np.zeros((9, 9))\n",
    "# for i in range(6):\n",
    "#     F[i, i + 3] = dt\n",
    "\n",
    "# G = np.zeros((9, 3))\n",
    "# for i in range(3):\n",
    "#     G[i + 6, i] = dt\n",
    "\n",
    "# H = np.zeros((6, 9))\n",
    "# for i in range(3):\n",
    "#     H[i, i] = dt\n",
    "#     H[i + 3, i + 6] = dt\n",
    "\n",
    "# # initial state\n",
    "# x0 = np.zeros(9)\n",
    "# P0 = 1e5 * Q\n",
    "# z = kal_data[\"PVS 1\"].to_numpy().T\n",
    "# print(type(z))\n",
    "# print(z.shape)\n",
    "# tsteps = 1000\n",
    "\n",
    "# # control u\n",
    "# u = np.zeros(3)\n",
    "\n",
    "# kf = KalmanFilter(F, Q, H, R, G, u)\n",
    "# est = kf.estimate(x0, P0, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot\n",
    "# plt.figure(figsize=(12,4))\n",
    "# plt.plot(est[0,:], est[1,:], label=\"Estimated Position\")\n",
    "# plt.scatter(z[0,:], z[1,:], label=\"Observations\", s = 1, c=\"g\")\n",
    "# plt.title(\"Observations and estimated position\")\n",
    "# plt.xlabel('x')\n",
    "# plt.ylabel('y')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM\n",
    "\n",
    "I got it to run (it turns out that you can only include one series as your input data) but it doesn't work. I think the HMM decided that zeros are local minimums or values below a threshold and pretty much everything else is ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good: 0, 1, 2, regular: 0, 1, 2, bad: 0, 1, 2, good: 0, 1, 2, regular: 0, 1, 2, bad: 0, 1, 2, good: 0, 1, 2, regular: 0, 1, 2, bad: 0, 1, 2, good: 0, 1, 2, regular: 0, 1, 2, bad: 0, 1, 2, good: 0, 1, 2, regular: 0, 1, 2, bad: 0, 1, 2, good: 0, 1, 2, regular: 0, 1, 2, bad: 0, 1, 2, good: 0, 1, 2, regular: 0, 1, 2, bad: 0, 1, 2, good: 0, 1, 2, regular: 0, 1, 2, bad: 0, 1, 2, "
     ]
    }
   ],
   "source": [
    "model_list = []\n",
    "for nc in range(2, 10):\n",
    "    print(\"\\n{nc} components:\")\n",
    "    models = {}\n",
    "    num_models = 3\n",
    "    for key in train_dict.keys():\n",
    "        # make data an array\n",
    "        data, lengths = train_dict[key]\n",
    "        data = data.values.reshape(-1, 1)\n",
    "        print(key, end=\": \")\n",
    "\n",
    "        best_log = -np.inf\n",
    "        best_model = None\n",
    "        for i in range(num_models):\n",
    "            # Initialize and train the model\n",
    "            model = hmm.GMMHMM(n_components=nc, covariance_type=\"diag\")\n",
    "            model.fit(data, lengths=lengths)\n",
    "            # Check the log-likelihood\n",
    "            log_likelihood = model.monitor_.history[-1]\n",
    "            if log_likelihood > best_log:\n",
    "                best_log = log_likelihood\n",
    "                best_model = model\n",
    "            print(i, end=\", \")\n",
    "        models[key] = best_model\n",
    "    \n",
    "    model_list.append(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components: 2\n",
      "Accuracy for good : 0.8181818181818182\n",
      "Accuracy for regular : 0.9\n",
      "Accuracy for bad : 0.0\n",
      "\n",
      "Number of components: 3\n",
      "Accuracy for good : 0.8181818181818182\n",
      "Accuracy for regular : 1.0\n",
      "Accuracy for bad : 0.0\n",
      "\n",
      "Number of components: 4\n",
      "Accuracy for good : 0.7272727272727273\n",
      "Accuracy for regular : 1.0\n",
      "Accuracy for bad : 0.0\n",
      "\n",
      "Number of components: 5\n",
      "Accuracy for good : 1.0\n",
      "Accuracy for regular : 1.0\n",
      "Accuracy for bad : 0.0\n",
      "\n",
      "Number of components: 6\n",
      "Accuracy for good : 0.7272727272727273\n",
      "Accuracy for regular : 0.6\n",
      "Accuracy for bad : 0.16666666666666666\n",
      "\n",
      "Number of components: 7\n",
      "Accuracy for good : 0.7272727272727273\n",
      "Accuracy for regular : 0.4\n",
      "Accuracy for bad : 0.5\n",
      "\n",
      "Number of components: 8\n",
      "Accuracy for good : 1.0\n",
      "Accuracy for regular : 1.0\n",
      "Accuracy for bad : 0.0\n",
      "\n",
      "Number of components: 9\n",
      "Accuracy for good : 0.6363636363636364\n",
      "Accuracy for regular : 0.6\n",
      "Accuracy for bad : 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predicted_labels = model.predict(X)\n",
    "\n",
    "def predict(mfcc_coeffs, index):\n",
    "    \"\"\"\n",
    "    Predict the word from the given mfcc coefficients\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mfcc_coeffs : ndarray of shape (M,)\n",
    "        The mfcc coefficients for the word to be predicted\n",
    "    index : int\n",
    "        The index of the model in the list of models\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    word : str\n",
    "        The predicted word\n",
    "    \"\"\"\n",
    "    # find the log probability density of the given mfcc coefficients\n",
    "    log_prob = {}\n",
    "    for key in model_list[index].keys():\n",
    "        log_prob[key] = model_list[index][key].score(mfcc_coeffs)\n",
    "    \n",
    "    # return the word with the highest probability\n",
    "    return max(log_prob, key=log_prob.get)\n",
    "\n",
    "\n",
    "\n",
    "time_window = 10 # seconds\n",
    "time_window *= 1000\n",
    "\n",
    "for j, nc in enumerate(range(2, 10)):\n",
    "    print(\"Number of components:\", nc)\n",
    "    for key in test_dict.keys():\n",
    "        correct = 0\n",
    "        incorrect = 0\n",
    "        test_data, _ = test_dict[key]\n",
    "\n",
    "        # iterate over test_data in groups of 10000\n",
    "        test_data = test_data.values.reshape(-1, 1)\n",
    "        for i in range(0, len(test_data), time_window):\n",
    "            item = test_data[i:i+time_window]\n",
    "            prediction = predict(item, j)\n",
    "            if prediction == key:\n",
    "                correct += 1\n",
    "            elif prediction == \"good\" and key == \"regular\":\n",
    "                correct += 1\n",
    "            elif prediction == \"regular\" and key == \"good\":\n",
    "                correct += 1\n",
    "            else:\n",
    "                incorrect += 1\n",
    "        \n",
    "        print(\"Accuracy for\", key, \":\", correct/(correct+incorrect))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters Set 1               Parameters Set 2\n",
      "------------------------------       ---------------\n",
      "algorithm: viterbi               algorithm: viterbi\n",
      "covariance_type: diag                  covariance_type: diag\n",
      "covars_prior:\n",
      "  - -1.5                    - -1.5\n",
      "  - -1.5                    - -1.5\n",
      "  - -1.5                    - -1.5\n",
      "  - -1.5                    - -1.5\n",
      "  - -1.5                    - -1.5\n",
      "  - -1.5                    - -1.5\n",
      "  - -1.5                    - -1.5\n",
      "  - -1.5                    - -1.5\n",
      "covars_weight:\n",
      "  - 0.0                     - 0.0\n",
      "  - 0.0                     - 0.0\n",
      "  - 0.0                     - 0.0\n",
      "  - 0.0                     - 0.0\n",
      "  - 0.0                     - 0.0\n",
      "  - 0.0                     - 0.0\n",
      "  - 0.0                     - 0.0\n",
      "  - 0.0                     - 0.0\n",
      "implementation: log                   implementation: log\n",
      "init_params: stmcw                 init_params: stmcw\n",
      "means_prior:\n",
      "  - 0.0                     - 0.0\n",
      "  - 0.0                     - 0.0\n",
      "  - 0.0                     - 0.0\n",
      "  - 0.0                     - 0.0\n",
      "  - 0.0                     - 0.0\n",
      "  - 0.0                     - 0.0\n",
      "  - 0.0                     - 0.0\n",
      "  - 0.0                     - 0.0\n",
      "means_weight:\n",
      "  - 0.0                     - 0.0\n",
      "  - 0.0                     - 0.0\n",
      "  - 0.0                     - 0.0\n",
      "  - 0.0                     - 0.0\n",
      "  - 0.0                     - 0.0\n",
      "  - 0.0                     - 0.0\n",
      "  - 0.0                     - 0.0\n",
      "  - 0.0                     - 0.0\n",
      "min_covar: 0.001                 min_covar: 0.001\n",
      "n_components: 8                     n_components: 8\n",
      "n_iter: 10                    n_iter: 10\n",
      "n_mix: 1                     n_mix: 1\n",
      "params: stmcw                 params: stmcw\n",
      "random_state: None       random_state: None\n",
      "startprob_prior: 1.0                   startprob_prior: 1.0\n",
      "tol: 0.01                  tol: 0.01\n",
      "transmat_prior: 1.0                   transmat_prior: 1.0\n",
      "verbose: False                 verbose: False\n",
      "weights_prior:\n",
      "  - 1.0                     - 1.0\n",
      "  - 1.0                     - 1.0\n",
      "  - 1.0                     - 1.0\n",
      "  - 1.0                     - 1.0\n",
      "  - 1.0                     - 1.0\n",
      "  - 1.0                     - 1.0\n",
      "  - 1.0                     - 1.0\n",
      "  - 1.0                     - 1.0\n"
     ]
    }
   ],
   "source": [
    "good_params = model_list[6][\"good\"].get_params()\n",
    "bad_params = model_list[6][\"bad\"].get_params()\n",
    "\n",
    "def pretty_print_parameters(parameters):\n",
    "    for key, value in parameters.items():\n",
    "        if isinstance(value, str):\n",
    "            print(f\"{key}: '{value}'\")\n",
    "        elif isinstance(value, bool):\n",
    "            print(f\"{key}: {str(value).lower()}\")\n",
    "        elif isinstance(value, (int, float)):\n",
    "            print(f\"{key}: {value}\")\n",
    "        elif isinstance(value, list):\n",
    "            print(f\"{key}:\")\n",
    "            for sub_value in value:\n",
    "                if isinstance(sub_value, list):\n",
    "                    for sub_sub_value in sub_value:\n",
    "                        print(f\"  - {sub_sub_value}\")\n",
    "                else:\n",
    "                    print(f\"  - {sub_value}\")\n",
    "        elif isinstance(value, np.ndarray):\n",
    "            print(f\"{key}:\")\n",
    "            for sub_value in value:\n",
    "                for sub_sub_value in sub_value:\n",
    "                    print(f\"  - {sub_sub_value}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value}\")\n",
    "\n",
    "def compare_parameter_sets(parameters1, parameters2):\n",
    "    max_key_length = max(len(key) for key in parameters1.keys())\n",
    "\n",
    "    print(\"Parameters Set 1\".ljust(max_key_length + 15), \"Parameters Set 2\")\n",
    "    print(\"-\" * (max_key_length + 15), \" \" * 5, \"-\" * max_key_length)\n",
    "\n",
    "    for key in parameters1.keys():\n",
    "        value1 = parameters1[key]\n",
    "        value2 = parameters2[key] if key in parameters2 else None\n",
    "\n",
    "        if isinstance(value1, (int, float, str, bool)):\n",
    "            print(f\"{key}: {str(value1).ljust(max_key_length)}\", \" \" * 5, f\"{key}: {value2}\")\n",
    "        elif isinstance(value1, list):\n",
    "            print(f\"{key}:\")\n",
    "            for sub_value1, sub_value2 in zip(value1, value2 or []):\n",
    "                print(f\"  - {str(sub_value1).ljust(max_key_length - 3)}\", \" \" * 8, f\"  - {sub_value2}\")\n",
    "        elif isinstance(value1, np.ndarray):\n",
    "            print(f\"{key}:\")\n",
    "            if value2 is not None and value1.shape == value2.shape:\n",
    "                flattened_value1 = value1.flatten()\n",
    "                flattened_value2 = value2.flatten()\n",
    "                for sub_value1, sub_value2 in zip(flattened_value1, flattened_value2):\n",
    "                    print(f\"  - {str(sub_value1).ljust(max_key_length - 3)}\", \" \" * 8, f\"  - {sub_value2}\")\n",
    "            else:\n",
    "                print(\"  Arrays are not of the same shape or one of them is None\")\n",
    "        else:\n",
    "            print(f\"{key}: {value1}\", \" \" * 5, f\"{key}: {value2}\")\n",
    "\n",
    "\n",
    "\n",
    "compare_parameter_sets(good_params, bad_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1813/3682354438.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# how many times does predicted_labels switch form 0 to 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mswitches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mswitches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predicted_labels' is not defined"
     ]
    }
   ],
   "source": [
    "# # how many times does predicted_labels switch form 0 to 1\n",
    "# switches = 0\n",
    "# for i in range(1, len(predicted_labels)):\n",
    "#     if predicted_labels[i] != predicted_labels[i-1]:\n",
    "#         switches += 1\n",
    "\n",
    "# print(f\"Switches: {switches}\")\n",
    "# print(f\"Length of labels: {len(predicted_labels)}\") \n",
    "# print(f\"Ratio: {switches/len(predicted_labels)}\")\n",
    "\n",
    "# # plot the predicted labels\n",
    "# start = 20000\n",
    "# end = 21000\n",
    "# diff = 1000\n",
    "# plt.figure(figsize=(20, 20))\n",
    "# p = 1\n",
    "# while p < 20:\n",
    "#     plt.subplot(5, 4, max(p,1))\n",
    "#     p += 1\n",
    "#     start += diff\n",
    "#     end += diff   \n",
    "#     a = predicted_labels[start:end]\n",
    "#     # count how many zeros\n",
    "#     zeros = np.count_nonzero(a == 0)\n",
    "#     # print(\"Zeros: \", zeros)\n",
    "#     # print(\"P:\", p)\n",
    "#     if zeros == 0:\n",
    "#         p -= 1\n",
    "#         continue\n",
    "#     plt.scatter(np.arange(diff), predicted_labels[start:end])\n",
    "#     plt.plot(np.arange(diff), hmm_true['paved_road'][start:end], color='red')\n",
    "#     plt.plot(np.arange(diff), X[start:end, 0]-9.5, color='green')\n",
    "#     plt.title(f\"Second {end/1000}, Zeros: {zeros}\")\n",
    "#     # remove axis ticks\n",
    "#     # plt.xticks([])\n",
    "#     # plt.yticks([])\n",
    "\n",
    "# # reduce space between subplots\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
